package promptdslcore

import (
	"fmt"
	"log"
	"os"
	"os/exec"
	"path/filepath"
	"regexp"
	"runtime"

	// "path/filepath"
	"promptdslcore/parser"
	"strconv"

	// "runtime"

	"strings"

	"github.com/antlr4-go/antlr/v4"
)

// eval
// log
func InitLog(logPath string) {
	logFile, err := os.OpenFile(logPath, os.O_CREATE|os.O_WRONLY|os.O_APPEND, 0666)
	if err != nil {
		log.Fatalf("æ— æ³•æ‰“å¼€æ—¥å¿—æ–‡ä»¶: %v", err)
	}
	log.SetOutput(logFile)
	log.SetFlags(log.Ldate | log.Ltime | log.Lshortfile)
}

// æ„å»ºè¾“å‡ºè§„èŒƒæ–‡æœ¬ï¼Œç”¨äºæ ¹æ®å­—æ®µåˆ—è¡¨ç”Ÿæˆ JSON å­—ç¬¦ä¸²è¡¨ç¤ºã€‚
func BuildOutputSpecLines(fields []FieldDef, asArray bool) []string {
	var lines []string
	if asArray {
		lines = append(lines, "```json")
		lines = append(lines, "[")
		lines = append(lines, "  {")
	} else {
		lines = append(lines, "```json")
		lines = append(lines, "{")
	}

	for i, f := range fields {
		var example string
		switch f.Type {
		case "string":
			example = "\"\""
		case "int":
			example = "0"
		case "float":
			example = "0.0"
		case "bool":
			example = "false"
		default:
			if strings.HasPrefix(f.Type, "[]") {
				elemType := f.Type[2:]
				switch elemType {
				case "string":
					example = "[\"\"]"
				case "int":
					example = "[0]"
				case "float":
					example = "[0.0]"
				case "bool":
					example = "[false]"
				default:
					example = "[]"
				}
			} else {
				example = "{}"
			}
		}

		// æ·»åŠ å­—æ®µåŠæ³¨é‡Š
		line := fmt.Sprintf("    \"%s\": %s  // %s", f.JsonName, example, strings.Join(f.Annotations, ","))
		if i < len(fields)-1 {
			line += ","
		}
		lines = append(lines, line)
	}

	if asArray {
		lines = append(lines, "  }")
		lines = append(lines, "]")
	} else {
		lines = append(lines, "}")
	}
	lines = append(lines, "```")

	return lines
}

func GenerateAfterAndFixGoCode(root *PromptNode, pkgName string) string {
	var b strings.Builder
	//ä¼ ä¸ªå‚è¿›æ¥
	outputTypeStr := "OutputContext"
	if root.outputspectNodes.IsArray {
		outputTypeStr = "[]OutputContext"
	}

	// å†™åŒ…åå’Œæ³¨é‡Š
	b.WriteString("// Code generated by PromptDSL. DO NOT EDIT.\n")
	b.WriteString(fmt.Sprintf("package %s\n\n", pkgName))

	//import
	afterCode := strings.Join(root.AfterCode, "\n")
	fixCode := strings.Join(root.FixCode, "\n")

	allCode := afterCode + "\n" + fixCode

	pkgs := inferImportsFromCode(allCode)

	// æ‰‹åŠ¨ä¿è¯ "os" åœ¨åŒ…åˆ—è¡¨é‡Œ
	requiredPkgs := []string{"os", "fmt"}
	for _, req := range requiredPkgs {
		has := false
		for _, pkg := range pkgs {
			if pkg == req {
				has = true
				break
			}
		}
		if !has {
			pkgs = append(pkgs, req)
		}
	}

	importBlock := renderImportSection(pkgs)
	b.WriteString(importBlock)

	// struct
	b.WriteString("type InputContext struct {\n")
	for _, field := range root.InFields {
		b.WriteString(fmt.Sprintf("    %s %s `json:\"%s\"`\n", field.Name, field.Type, field.JsonName))
	}
	b.WriteString("}\n\n")
	b.WriteString("type OutputContext struct {\n")
	for _, field := range root.OutFields {
		fieldName := capitalizeFirst(field.Name)
		b.WriteString(fmt.Sprintf("    %s %s `json:\"%s\"`\n", fieldName, field.Type, field.JsonName))
	}
	b.WriteString("}\n\n")

	b.WriteString("type FinalContext struct {\n")
	b.WriteString("    Input  InputContext\n")
	b.WriteString(fmt.Sprintf("    Output %s\n", outputTypeStr))
	b.WriteString("}\n\n")

	// å†™å…¥ After å‡½æ•°ï¼ˆå¦‚æœæœ‰ï¼‰

	if strings.TrimSpace(root.AfterCode[0]) != "" {
		b.WriteString(fmt.Sprintf("func AfterProcess(output %s) %s {\n", outputTypeStr, outputTypeStr))
		b.WriteString(root.AfterCode[0])
		b.WriteString("\n}\n\n")
	}

	// å†™å…¥ Fix å‡½æ•°ï¼ˆå¦‚æœæœ‰ï¼‰
	if strings.TrimSpace(root.FixCode[0]) != "" {
		b.WriteString(fmt.Sprintf("func FixProcess(response string) (%s ,error){\n", outputTypeStr))
		b.WriteString(root.FixCode[0])
		b.WriteString("\n}\n")
	}

	// å†™ main å‡½æ•°
	b.WriteString("\nfunc main() {\n")
	// å…¥å£æ‰“å°
	b.WriteString("    fmt.Fprintln(os.Stderr, \"[main] ç¨‹åºå¯åŠ¨ï¼Œç­‰å¾…è¾“å…¥...\")\n")
	b.WriteString("    inputBytes, err := os.ReadFile(\"model_output.json\")\n")
	b.WriteString("    if err != nil {\n")
	b.WriteString("        fmt.Fprintf(os.Stderr, \"è¯»å–è¾“å…¥å¤±è´¥: %v\\n\", err)\n")
	b.WriteString("        os.Exit(1)\n")
	b.WriteString("    }\n\n")

	hasFix := strings.TrimSpace(fixCode) != ""
	hasAfter := strings.TrimSpace(afterCode) != ""

	if hasFix {

		b.WriteString("    output,err := FixProcess(string(inputBytes))\n")
		b.WriteString("    if err != nil {\n")
		b.WriteString("        fmt.Fprintf(os.Stderr, \"è§£æè¾“å…¥ JSON å¤±è´¥011111: %v\\n\", err)\n")
		b.WriteString("        os.Exit(1)\n")
		b.WriteString("    }\n")
		if hasAfter {
			b.WriteString("    output = AfterProcess(output)\n")
		}

	} else if hasAfter {
		b.WriteString(fmt.Sprintf("    var output %s\n", outputTypeStr))
		b.WriteString("    if err := json.Unmarshal(inputBytes, &output); err != nil {\n")
		b.WriteString("        fmt.Fprintf(os.Stderr, \"è§£æè¾“å…¥ JSON å¤±è´¥011111: %v\\n\", err)\n")
		b.WriteString("        os.Exit(1)\n")
		b.WriteString("    }\n")
		b.WriteString("    output = AfterProcess(output)\n")
	} else {
		b.WriteString("    fmt.Println(\"æœªå®šä¹‰ FixProcess æˆ– AfterProcess\")\n")
		b.WriteString("    return\n")
	}

	b.WriteString("\n    encoded, err := json.Marshal(output)\n")
	b.WriteString("    if err != nil {\n")
	b.WriteString("        fmt.Fprintf(os.Stderr, \"è¾“å‡ºç¼–ç å¤±è´¥: %v\\n\", err)\n")
	b.WriteString("        os.Exit(1)\n")
	b.WriteString("}\n")
	b.WriteString("    fmt.Println(string(encoded))\n")
	b.WriteString("}\n")

	return b.String()
}

func getCurrentPackageName() string {
	_, file, _, ok := runtime.Caller(1)
	if !ok {
		return "main"
	}
	// è·å–è·¯å¾„ä¸­çš„ç›®å½•åä½œä¸ºâ€œåŒ…åâ€
	dir := filepath.Base(filepath.Dir(file))
	return dir
}
func extractRawText(ctx antlr.ParserRuleContext, tokens *antlr.CommonTokenStream) []string {
	startIdx := ctx.GetStart().GetTokenIndex()
	stopIdx := ctx.GetStop().GetTokenIndex()

	// è·å–å®Œæ•´ token åˆ—è¡¨
	allTokens := tokens.GetAllTokens()

	// åˆ‡ç‰‡æˆªå– ctx èŒƒå›´å†…çš„ token
	if startIdx < 0 || stopIdx >= len(allTokens) || startIdx > stopIdx {
		return nil
	}

	var builder strings.Builder
	for _, tok := range allTokens[startIdx : stopIdx+1] {
		builder.WriteString(tok.GetText())
	}
	code := builder.String()
	rePrefix := regexp.MustCompile(`(?i)^\s*(after|fix)\s*{`)
	code = rePrefix.ReplaceAllString(code, "")
	code = strings.TrimSuffix(code, "}")
	return []string{code}
}

func capitalizeFirst(s string) string {
	if len(s) == 0 {
		return s
	}
	return strings.ToUpper(s[:1]) + s[1:]
}
func renderImportSection(pkgs []string) string {
	if len(pkgs) == 0 {
		return ""
	}
	var b strings.Builder
	b.WriteString("import (\n")
	for _, pkg := range pkgs {
		b.WriteString(fmt.Sprintf("\t\"%s\"\n", pkg))
	}
	b.WriteString(")\n\n")
	return b.String()
}
func inferImportsFromCode(code string) []string {
	importSet := map[string]struct{}{}

	for prefix, pkg := range symbolToImport {
		if strings.Contains(code, prefix) {
			importSet[pkg] = struct{}{}
		}
	}

	var imports []string
	for pkg := range importSet {
		imports = append(imports, pkg)
	}
	// sort.Strings(imports) // å¯é€‰ï¼šè®© import æœ‰åº
	return imports
}
func renderImportSectionWithAlias(goimports []goimport, pkgs []string) string {
    var b strings.Builder
    b.WriteString("import (\n")
    
    // å…ˆæŠŠå¸¦åˆ«åçš„ goimports å†™è¿›å»
    for _, imp := range goimports {
        if imp.Alias != "" {
            b.WriteString(fmt.Sprintf("\t%s \"%s\"\n", imp.Alias, imp.Path))
        } else {
            b.WriteString(fmt.Sprintf("\t\"%s\"\n", imp.Path))
        }
    }

    // æŠŠçº¯è·¯å¾„ pkgs é‡Œæ²¡æœ‰åœ¨ goimports é‡Œå‡ºç°çš„è·¯å¾„è¡¥ä¸Šï¼ˆæ— åˆ«åï¼‰
    exist := map[string]bool{}
    for _, imp := range goimports {
        exist[imp.Path] = true
    }
    for _, pkg := range pkgs {
        if !exist[pkg] {
            b.WriteString(fmt.Sprintf("\t\"%s\"\n", pkg))
        }
    }

    b.WriteString(")\n\n")
    return b.String()
}
func extractFieldDef(field parser.IFieldDefContext, defaultAnnoMap map[string][]string) FieldDef {
	name := field.ID().GetText()
	typ := field.Type_().GetText()
	jsonName := name
	var annotations []string
	var subFields []FieldDef

	// typeCtx := field.Type_()

	// // åˆ¤æ–­æ˜¯å¦ä¸º struct ç±»å‹
	// if structType := typeCtx.GetChild(0); structType != nil {
	// 	if structKeyword, ok := structType.(antlr.TerminalNode); ok && structKeyword.GetText() == "struct" {
	// 		// æ‰‹åŠ¨è®¿é—® struct çš„å­—æ®µå®šä¹‰
	// 		// éå† Type_() çš„å­èŠ‚ç‚¹ï¼Œæ‰¾å‡º fieldDef
	// 		for i := 0; i < typeCtx.GetChildCount(); i++ {
	// 			child := typeCtx.GetChild(i)
	// 			if fdCtx, ok := child.(*parser.FieldDefContext); ok {
	// 				subFields = append(subFields, extractFieldDef(fdCtx, defaultAnnoMap))
	// 			}
	// 		}
	// 	}
	// }

	// æ³¨è§£å¤„ç†ï¼ˆä¸å˜ï¼‰
	for _, ann := range field.AllAnnotation() {
		annName := ann.ID().GetText()
		if ann.AnnotationArgs() != nil {
			for _, v := range ann.AnnotationArgs().AllAnnotationValue() {
				var val string
				if s := v.STRING(); s != nil {
					raw := s.GetText()
					unquoted, err := strconv.Unquote(raw)
					if err != nil {
						unquoted = raw
					}
					val = unquoted
				} else if arr := v.ArrayLiteral(); arr != nil {
					var parts []string
					for _, s := range arr.AllSTRING() {
						raw := s.GetText()
						unquoted, err := strconv.Unquote(raw)
						if err != nil {
							unquoted = raw
						}
						parts = append(parts, unquoted)
					}
					val = strings.Join(parts, ",")
				}
				if annName == "jsonname" {
					jsonName = val
				} else {
					annotations = append(annotations, val)
				}
			}
		}
		if defVals, ok := defaultAnnoMap[annName]; ok {
			annotations = append(annotations, defVals...)
		}
	}

	return FieldDef{
		Name:        name,
		Type:        typ,
		JsonName:    jsonName,
		Annotations: annotations,
		SubFields:   subFields,
	}
}

type Range struct {
	start int
	end   int
}

// Function to extract code blocks from the token stream
func extractCodeBlocks(tokens *antlr.CommonTokenStream, typ string) Range {

	// Get all tokens
	allTokens := tokens.GetAllTokens()

	ret := Range{-1, -1}

	t := parser.PromptDSLLexerFIX
	if typ == "after" {
		t = parser.PromptDSLLexerAFTER
	}
	fmt.Println("t:", t)
	// Track brace nesting level
	braceLevel := 0

	for i, token := range allTokens {
		typel := token.GetTokenType()
		fmt.Println("typel:", typel)
		if token.GetTokenType() == t {
			fmt.Println("ğŸ˜®")
			ret.start = i
			braceLevel = 0
			// Find the opening brace
			for j := i + 1; j < len(allTokens); j++ {
				if allTokens[j].GetTokenType() == parser.PromptDSLParserLBRACE {
					// Find the matching closing brace
					for k := j + 1; k < len(allTokens); k++ {
						if allTokens[k].GetTokenType() == parser.PromptDSLParserLBRACE {
							braceLevel++
						} else if allTokens[k].GetTokenType() == parser.PromptDSLParserRBRACE {
							if braceLevel == 0 {
								ret.end = k
								break
							}
							braceLevel--
						}
					}
					break
				}
			}
		}
	}

	return ret
}
func slej() {
	for i := 0; i < 10; i++ {
		fmt.Println(i)
	}
}

// è°ƒç”¨ go get å®‰è£…é¢å¤–çš„ä¾èµ–
func installGoImports(goimports []goimport, workDir string) error {
	for _, pkg := range goimports {
		// æ ‡å‡†åº“å¦‚ "fmt"ã€"os" ä¸éœ€è¦ go get
		if isStandardPackage(pkg.Path) {
			continue
		}

		cmd := exec.Command("go", "get", pkg.Path)
		cmd.Dir = workDir
		out, err := cmd.CombinedOutput()
		if err != nil {
			return fmt.Errorf("failed to go get %s: %v\nOutput: %s", pkg, err, string(out))
		}
	}
	return nil
}

// ç®€å•åˆ¤æ–­æ˜¯ä¸æ˜¯æ ‡å‡†åº“
func isStandardPackage(pkg string) bool {
	stdPkgs := map[string]bool{
		"fmt": true, "os": true, "io": true, "strings": true, "time": true, "bytes": true,
	}
	return stdPkgs[pkg]
}
